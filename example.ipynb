{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_changepoint_detection(data, hazard_func, observation_likelihood):\n",
    "    maxes = np.zeros(len(data) + 1)\n",
    "    \n",
    "    R = np.zeros((len(data) + 1, len(data) + 1))\n",
    "    R[0, 0] = 1\n",
    "    \n",
    "    for t, x in enumerate(data):\n",
    "        # Evaluate the predictive distribution for the new datum under each of\n",
    "        # the parameters.  This is the standard thing from Bayesian inference.\n",
    "        predprobs = observation_likelihood.pdf(x)\n",
    "        \n",
    "        # Evaluate the hazard function for this interval\n",
    "        H = hazard_func(np.array(range(t+1)))\n",
    "       \n",
    "        # Evaluate the growth probabilities - shift the probabilities down and to\n",
    "        # the right, scaled by the hazard function and the predictive\n",
    "        # probabilities.\n",
    "        R[1:t+2, t+1] = R[0:t+1, t] * predprobs * (1-H)\n",
    "        \n",
    "        # Evaluate the probability that there *was* a changepoint and we're\n",
    "        # accumulating the mass back down at r = 0.\n",
    "        R[0, t+1] = np.sum( R[0:t+1, t] * predprobs * H)\n",
    "        \n",
    "        # Renormalize the run length probabilities for improved numerical\n",
    "        # stability.\n",
    "        R[:, t+1] = R[:, t+1] / np.sum(R[:, t+1])\n",
    "        \n",
    "        # Update the parameter sets for each possible run length.\n",
    "        observation_likelihood.update_theta(x)\n",
    "    \n",
    "        maxes[t] = R[:, t].argmax()\n",
    "    return R, maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_hazard(lam, r):\n",
    "    return 1/lam * np.ones(r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentT:\n",
    "    def __init__(self, alpha, beta, kappa, mu):\n",
    "        self.alpha0 = self.alpha = np.array([alpha])\n",
    "        self.beta0 = self.beta = np.array([beta])\n",
    "        self.kappa0 = self.kappa = np.array([kappa])\n",
    "        self.mu0 = self.mu = np.array([mu])\n",
    "\n",
    "    def pdf(self, data):\n",
    "        return stats.t.pdf(x=data, \n",
    "                           df=2*self.alpha,\n",
    "                           loc=self.mu,\n",
    "                           scale=np.sqrt(self.beta * (self.kappa+1) / (self.alpha *\n",
    "                               self.kappa)))\n",
    "\n",
    "    def update_theta(self, data):\n",
    "        muT0 = np.concatenate((self.mu0, (self.kappa * self.mu + data) / (self.kappa + 1)))\n",
    "        kappaT0 = np.concatenate((self.kappa0, self.kappa + 1.))\n",
    "        alphaT0 = np.concatenate((self.alpha0, self.alpha + 0.5))\n",
    "        betaT0 = np.concatenate((self.beta0, self.beta + (self.kappa * (data -\n",
    "            self.mu)**2) / (2. * (self.kappa + 1.))))\n",
    "            \n",
    "        self.mu = muT0\n",
    "        self.kappa = kappaT0\n",
    "        self.alpha = alphaT0\n",
    "        self.beta = betaT0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1,3,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = online_changepoint_detection(data, partial(constant_hazard, 250), StudentT(10, .03, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 4.00000000e-03 4.00000000e-03 4.00000000e-03\n",
      "  4.00000000e-03]\n",
      " [0.00000000e+00 9.96000000e-01 2.85265914e-12 3.24324646e-01\n",
      "  9.75320585e-03]\n",
      " [0.00000000e+00 0.00000000e+00 9.96000000e-01 1.37562376e-12\n",
      "  9.36245130e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 6.71675354e-01\n",
      "  1.12177227e-13]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  5.00016638e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.03908841e-20])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StudentT(10, .03, 1, 0).pdf(data[1])*(249/250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.63015599e-22])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StudentT(10, .03, 1, 0).pdf(data[1])*(1/250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004000000002247837"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.63015599e-22/(9.03908841e-20+3.63015599e-22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blog "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginal Probability $P(x) = \\sum_{y}P(x,y)$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional Probabilty $P(x | y) = \\frac{P(x,y)}{P(y)}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes Theorem\n",
    ">$P(\\theta | D ) \\propto P(D | \\theta) * P(\\theta)$ \\\n",
    "$posterior = likelihood * prior$\\\n",
    "<br>\n",
    "Lets try to define some distributions,\\\n",
    "$D \\propto pdf(\\theta)$\\\n",
    "$\\theta \\propto pdf(\\gamma)$\\\n",
    "Now, $\\gamma$ is a hyperprior, which can either by a r.v or can be constant\\\n",
    "So when we recieve data, we update our beliefs i.e hyperprior.\\\n",
    "<br> \n",
    "Now when $\\gamma$ is not a r.v (i.e it does not follow any distribution), then:<br>\n",
    "$P(\\theta | D,\\gamma ) \\propto P(D | \\theta, \\gamma) * P(\\theta | \\gamma)$\\\n",
    "$P(\\theta | D,\\gamma ) \\propto P(D | \\theta) * P(\\theta)$ , assuming D is independent of every thing when conditioned on $\\theta$,  this can go wrong is the data points are not iid, for example time series data with significant auto-correlation.\\\n",
    "<br>\n",
    "When $\\gamma$ also follows a distribution, then:<br> \n",
    "$P(\\theta | D,\\gamma ) \\propto P(D | \\theta, \\gamma)*P(\\theta | \\gamma)$\\\n",
    "$P(\\theta | D,\\gamma )*P(\\gamma) \\propto P(D | \\theta, \\gamma)*P(\\theta | \\gamma) * P(\\gamma)$\\\n",
    "$P(\\theta,\\gamma | D ) \\propto P(D | \\theta, \\gamma)*P(\\theta | \\gamma) * P(\\gamma)$ , conditional probabilty\\\n",
    "$P(\\theta,\\gamma | D ) \\propto P(D | \\theta)*P(\\theta | \\gamma) * P(\\gamma)$ , assuming D is independent of every thing when conditioned on $\\theta$\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Whats the use?<br>\n",
    "Economics, genetics, anomoly detection, stock market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defn 1 :\n",
    "t : some time \\\n",
    "$x_t$ : observed data at time t<br>\n",
    "$x_{1:t}$ : $x_1,x_2,....x_{t-1}, x_t$<br>\n",
    "$x_t^r$ : data points in current run\\\n",
    "$r_t$ : run length at time t ( number of time points from last change point)<br>\n",
    "Change point is when $r_t = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What we want to achieve?\n",
    "We want to figure out if the recieved data point is a change point, i.e $P(r_t | x_{1:t})$\\\n",
    "We want to be able to predict the next data point, i.e $P(x_{t+1} | x_{1:t})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumption 1 :<br>\n",
    "Data can be divided into several partitions, data points in each partition are iid's, i.e $x_t^r \\propto pdf(\\eta)$\\\n",
    "$x_t^r$ is conditionally independent of everything given $\\eta$\\\n",
    "$r_t$ is conditionally independent of everything given $r_{t-1}$ -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the predictive version<br>\n",
    "\n",
    "$P(x_{t+1}|x_{1:t}) = \\sum_{r_t}P(x_{t+1}|r_t,x_{1:t})*P(r_t | x_{1:t})$ , this comes from conditional and marginal probability<br>\n",
    "\n",
    "Since $x_{t+1}$ only depend on $x_t^r$<br>\n",
    "$P(x_{t+1}|x_{1:t}) = \\sum_{r_t}P(x_{t+1}|r_t,x_t^r)*P(r_t | x_{1:t})$\n",
    "\n",
    "$P(r_t | x_{1:t}) = \\frac{P(r_t , x_{1:t})}{P(x_{1:t})}$, from bayes theorem\n",
    "\n",
    "Hence to have predictive version in place we need 3 things, $P(r_t , x_{1:t}), P(x_{1:t}), P(x_{t+1}|r_t,x_t^r)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changepoint Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(r_t,x_{1:t}) = \\sum_{r_{t-1}}P(r_t,x_{1:t}, r_{t-1})$ *this again from marginal distribution, P(A) = $\\sum_{\\forall b}P(A,B)$*<br>\n",
    "$P(r_t,x_{1:t}) = \\sum_{r_{t-1}}P(r_t,x_{1:t-1}, r_{t-1},x_t)$ *just split $x_{1:t}$*<br>\n",
    "$P(r_t,x_{1:t}) = \\sum_{r_{t-1}}P(r_t,x_t | x_{1:t-1}, r_{t-1})*P(x_{1:t-1}, r_{t-1})$ *this is just P(A,B) = P(A|B)P(B)*<br>\n",
    "\n",
    "\n",
    "$P(r_t,x_{1:t}) = \\sum_{r_{t-1}}P(x_t | r_t, x_{1:t-1}, r_{t-1})*P(r_t|x_{1:t-1}, r_{t-1})*P(x_{1:t-1}, r_{t-1})$ , using chain rule<br>\n",
    "$P(r_t,x_{1:t}) = \\sum_{r_{t-1}}P(r_t|r_{t-1})*P(x_t | x_{1:t-1}, r_{t-1})*P(x_{1:t-1}, r_{t-1})$ , *$r_t$ only depends on $r_{t-1}$*<br>\n",
    "$P(r_t,x_{1:t}) = \\sum_{r_{t-1}}P(r_t|r_{t-1})*P(x_t | x_{t-1}^{r_{t-1}}, r_{t-1})*P(x_{1:t-1}, r_{t-1})$ ,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References \n",
    "\n",
    "https://nbviewer.jupyter.org/github/hildensia/bayesian_changepoint_detection/blob/master/Example%20Code.ipynb\n",
    "https://arxiv.org/pdf/0710.3742.pdf\n",
    "http://gregorygundersen.com/blog/2019/08/13/bocd/#:~:text=Bayesian%20online%20changepoint%20detection%20is,modularity%20and%20efficient%20parameter%20estimation\n",
    "https://github.com/hildensia/bayesian_changepoint_detection/blob/master/bayesian_changepoint_detection/\n",
    "https://en.wikipedia.org/wiki/Forward_algorithm#Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
